{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ivan137950/Russian-Language-Toxic-Comments/blob/main/Gas_Myas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "J_zx8tkMGWtV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Russian Language Toxic Comments\n",
        "https://www.kaggle.com/datasets/blackmoon/russian-language-toxic-comments/data"
      ],
      "metadata": {
        "id": "b-_Sax26tFwT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfduxqljTCYT"
      },
      "outputs": [],
      "source": [
        "!install-update pip\n",
        "!pip install bertopic\n",
        "# !pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "W4ocu5-ATGj9"
      },
      "outputs": [],
      "source": [
        "# import optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Y7kp2mPqLDW"
      },
      "source": [
        "---\n",
        "# Скачаем данные в гугл коллаб\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "vmuk2SjgZD3O"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OO0LetZI_bEM"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHCYsbCM_SGz"
      },
      "outputs": [],
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGR3fZfJ_T1l"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets download -d blackmoon/russian-language-toxic-comments\n",
        "!unzip russian-language-toxic-comments.zip -d /content/datafr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzL9Dpx3_C1c"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(pd.read_csv(\"/content/datafr/labeled.csv\")) # Итоговая бд\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# ***Предварительный анализ данных.***\n",
        "Посмотрим на структуру имеющихся данных, чтобы понять, как с ними лучше работать.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "aZ_yp38G0yHh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1YL8ysgo2M4"
      },
      "outputs": [],
      "source": [
        "ax = sns.histplot(df['toxic'], bins=2, color='purple') #I love purple\n",
        "\n",
        "for p in ax.patches:\n",
        "    ax.annotate(f'{int(p.get_height())}',\n",
        "                (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                ha='center', va='bottom')\n",
        "\n",
        "ax.set_xticks([1/4, 3/4])\n",
        "ax.set_xticklabels(['Нейтральные', 'Негативные'])\n",
        "\n",
        "plt.ylabel('Количество')\n",
        "plt.xlabel('Комментарии')\n",
        "plt.title('Гистограмма')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbrheCjHrJZR"
      },
      "source": [
        "Видно, что негативных комментариев значительно меньше, и ,при неправильном разеделении датасета на тестовые и проверочные данные, классификатор будет выдавать только 0. Теперь займёся самими комментариями."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jKz90srwXWA"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "df['clean-text'] = df['comment'].str.lower()\n",
        "df['clean-text'] = [re.sub(r'[,.!?/\\\"-=+%*^$<>#():;]', \" \" , text[:-1]) for text in df['clean-text']]\n",
        "df['clean-text'] = df['clean-text'].str.split()\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viB-SgwchzRB"
      },
      "source": [
        "Рассмотрим топ 25 самых популярных слов\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbCTTz1y9nri"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "\n",
        "count_dict = Counter()\n",
        "for i in range(len(df)):\n",
        "    count_dict.update(df['clean-text'][i])\n",
        "\n",
        "count_dict = dict(sorted(count_dict.items(),\n",
        "                         key=lambda item: item[1],\n",
        "                         reverse=True))\n",
        "\n",
        "total_amount = sum(count_dict.values())\n",
        "count_dict_avg = {item[0]:\n",
        "               item[1] / total_amount\n",
        "               for item in count_dict.items()}\n",
        "# count_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLpsa4w0YF2W"
      },
      "outputs": [],
      "source": [
        "keys = list(count_dict.keys())[:100]\n",
        "values = list(count_dict.values())[:100]\n",
        "\n",
        "# Создание гистограммы\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "plt.bar(keys[:25], values[:25])\n",
        "plt.xlabel(\"слова\")\n",
        "plt.ylabel(\"Частота\")\n",
        "plt.title(\"Частота слов в сообщениях\")\n",
        "plt.grid(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mByc_gH5lMPg"
      },
      "source": [
        "---\n",
        "Видно, что на первых позициях стоят слова, которые, очевидно, одинаково часто встречаются как в грубых, так и в самых невинных комментариях. Давайте найдём те слова, которые одинаково часто встречаются и там, и там, и те слова, которые наоборот, встрчеаются в одном из случаев сильно чаще, чем в другом. Так как негативных коментариев вдвое меньше, буду брать не абсолютные значения, а относительные.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4MO4bGTlLi9"
      },
      "outputs": [],
      "source": [
        "#Разбиваю df на 2 части\n",
        "comments_neg = df[df['toxic'] == 1]['clean-text']\n",
        "comments_pos = df[df['toxic'] == 0]['clean-text']\n",
        "comments_pos.shape, comments_neg.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGEu35Xrno0W"
      },
      "outputs": [],
      "source": [
        "#Сколько раз каждое слово попало в каждую группу\n",
        "count_dict_pos = Counter()\n",
        "for com in comments_pos:\n",
        "    count_dict_pos.update(com)\n",
        "count_dict_pos = dict(sorted(count_dict_pos.items(),\n",
        "                             key=lambda item: item[1],\n",
        "                             reverse=True))\n",
        "\n",
        "count_dict_neg = Counter()\n",
        "for com in comments_neg:\n",
        "    count_dict_neg.update(com)\n",
        "\n",
        "count_dict_neg = dict(sorted(count_dict_neg.items(),\n",
        "                             key=lambda item: item[1],\n",
        "                             reverse=True))\n",
        "# count_dict_neg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EhceWDHOpWGW"
      },
      "outputs": [],
      "source": [
        "#Сколько раз каждое слово попало в каждую группу в процентном соотношении\n",
        "pos_total_amount = sum(count_dict_pos.values())\n",
        "neg_total_amount = sum(count_dict_neg.values())\n",
        "\n",
        "avg_dic_pos = {item[0]:\n",
        "               item[1] / pos_total_amount\n",
        "               for item in count_dict_pos.items()}\n",
        "\n",
        "avg_dic_neg = {item[0]:\n",
        "               item[1] / neg_total_amount\n",
        "               for item in count_dict_neg.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDR1Dj48t4fO"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Найдём слова, вероятность которых найти в негативных комментариях сильно\n",
        "меньше, сильно больше и приблизительно равна вероятности найти их в позитивных,\n",
        "а также выделим слова, которые встречаются только в одном из классов\n",
        "'''\n",
        "\n",
        "pos_set = set(item[0] for item in avg_dic_pos.items())\n",
        "neg_set = set(item[0] for item in avg_dic_neg.items())\n",
        "pos_only_arr = list(pos_set - neg_set) #есть только в позитивных комментариях\n",
        "neg_only_arr = list(neg_set - pos_set) #есть только в негативных комментариях\n",
        "neg_pos_arr = list(neg_set & pos_set)  #есть в любых комментариях\n",
        "len(pos_only_arr), len(neg_only_arr), len(neg_pos_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zI0v4F8SWdHR"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "И теперь для каждого множества из предыдущего пункта зададим таблицы\n",
        "'''\n",
        "#встречаются только в позитивных комментариях\n",
        "tot_avg = [count_dict_avg[pos] for pos in pos_only_arr]\n",
        "pos_avg = [avg_dic_pos[pos] for pos in pos_only_arr]\n",
        "\n",
        "pos_df = df[df['toxic'] == 0]\n",
        "pos_words = [word for arr in pos_df['clean-text'] for word in arr]\n",
        "word_counts = Counter(pos_words)\n",
        "pos_amount = [word_counts.get(word, 0) for word in pos_only_arr]\n",
        "\n",
        "pos_only_df = pd.DataFrame({\"words\": pos_only_arr,\n",
        "                            \"percantage-in-all-words\": tot_avg,\n",
        "                            \"percantage-in-pos-words\": pos_avg,\n",
        "                            \"amount-in-messages\": pos_amount})\n",
        "pos_only_df = pos_only_df.sort_values(by=\"amount-in-messages\", ascending=False)\n",
        "pos_only_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQKrg8-diEDZ"
      },
      "outputs": [],
      "source": [
        "#встречаются только в негативных комментариях\n",
        "tot_avg = [count_dict_avg[neg] for neg in neg_only_arr]\n",
        "neg_avg = [avg_dic_neg[neg] for neg in neg_only_arr]\n",
        "\n",
        "neg_df = df[df['toxic'] == 1]\n",
        "neg_words = [word for arr in neg_df['clean-text'] for word in arr]\n",
        "word_counts = Counter(neg_words)\n",
        "neg_amount = [word_counts.get(word, 0) for word in neg_only_arr]\n",
        "\n",
        "neg_only_df = pd.DataFrame({\"words\": neg_only_arr,\n",
        "                            \"percantage-in-all-words\": tot_avg,\n",
        "                            \"percantage-in-neg-words\": neg_avg,\n",
        "                            \"amount-in-messages\": neg_amount})\n",
        "neg_only_df = neg_only_df.sort_values(by=\"amount-in-messages\", ascending=False)\n",
        "neg_only_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLk3zXU3I2XK"
      },
      "outputs": [],
      "source": [
        "#встречаются и в позитивных, и в негативных комментариях\n",
        "neg_pos_pos = [avg_dic_pos[pos] for pos in neg_pos_arr]\n",
        "neg_pos_neg = [avg_dic_neg[neg] for neg in neg_pos_arr]\n",
        "neg_to_pos  = [neg_pos_pos[i] / neg_pos_neg[i] for i in range(len(neg_pos_arr))]\n",
        "pos_to_neg  = [1 / ntp for ntp in neg_to_pos]\n",
        "total_dict = [count_dict_avg[elem] for elem in neg_pos_arr]\n",
        "\n",
        "\n",
        "#количество негативных комментариев со словами из npa\n",
        "neg_df = df[df['toxic'] == 1]\n",
        "neg_words = [word for arr in neg_df['clean-text'] for word in arr]\n",
        "word_counts = Counter(neg_words)\n",
        "neg_amount_npa = [word_counts.get(word, 0) for word in neg_pos_arr]\n",
        "\n",
        "\n",
        "#количество позитивных комментариев со словами из npa\n",
        "pos_df = df[df['toxic'] == 0]\n",
        "pos_words = [word for arr in pos_df['clean-text'] for word in arr]\n",
        "word_counts = Counter(pos_words)\n",
        "pos_amount_npa = [word_counts.get(word, 0) for word in neg_pos_arr]\n",
        "\n",
        "\n",
        "\n",
        "neg_pos_df = pd.DataFrame({\"words\": neg_pos_arr,\n",
        "                           \"positive\": neg_pos_pos,\n",
        "                           \"negative\": neg_pos_neg,\n",
        "                           \"total\": total_dict,\n",
        "                           \"more-positive\": neg_to_pos,\n",
        "                           \"more-negative\": pos_to_neg,\n",
        "                           \"pos-comments-amount\": pos_amount_npa,\n",
        "                           \"neg-comments-amount\": neg_amount_npa\n",
        "                           })\n",
        "\n",
        "\n",
        "neg_pos_df[\"all-comments-amount\"] = neg_pos_df['neg-comments-amount'] + neg_pos_df['pos-comments-amount']\n",
        "neg_pos_df =  neg_pos_df.sort_values(by=\"all-comments-amount\", ascending=False)\n",
        "neg_pos_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T74yOAUc-n5N"
      },
      "source": [
        "Посмотрим на гистограммы, в которых колонки отвечают за количество слов в том или ином наборе"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtEJrN94-mXB"
      },
      "outputs": [],
      "source": [
        "# Функция распределения для amount-in-messages в pos_only_df\n",
        "pos_hist_df = pos_only_df['amount-in-messages'].apply(\n",
        "                                              lambda x: x if x < 11 else 11)\n",
        "\n",
        "pos_hist_arr = np.sort(np.array([phd for phd in pos_hist_df]))\n",
        "pos_hist_arr = np.array([\n",
        "                    str(phd) if phd < 11 else \">10\"  for phd in pos_hist_df])\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(18, 8))\n",
        "hist_plot = sns.histplot(pos_hist_arr,\n",
        "                        binwidth=1,\n",
        "                        stat='density',\n",
        "                        cumulative=True,\n",
        "                        ax=ax)\n",
        "plt.xlim(-1, 11)\n",
        "\n",
        "\n",
        "plt.xlabel(\"частота\")\n",
        "plt.ylabel(\"amount in messages\")\n",
        "plt.title(\"распределение amount-in-messages для позитивных комментариев\")\n",
        "for p in hist_plot.patches:\n",
        "    height = p.get_height()\n",
        "    if height > 0:\n",
        "        ax.text(\n",
        "            p.get_x() + p.get_width() / 2,\n",
        "            height,\n",
        "            f'{height:.2f}',\n",
        "            ha='center',\n",
        "            va='bottom'\n",
        "        )\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTi17FZqGBsQ"
      },
      "outputs": [],
      "source": [
        "# Функция распределения для amount-in-messages в neg_only_df\n",
        "neg_hist_df = neg_only_df['amount-in-messages'].apply(\n",
        "                                              lambda x: x if x < 11 else 11)\n",
        "\n",
        "neg_hist_arr = np.sort(np.array([phd for phd in neg_hist_df]))\n",
        "neg_hist_arr = np.array([\n",
        "                    str(phd) if phd < 11 else \">10\"  for phd in neg_hist_df])\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(18, 8))\n",
        "hist_plot = sns.histplot(neg_hist_arr,\n",
        "                        binwidth=1,\n",
        "                        stat='density',\n",
        "                        cumulative=True,\n",
        "                        ax=ax)\n",
        "plt.xlim(-1, 11)\n",
        "\n",
        "\n",
        "plt.xlabel(\"частота\")\n",
        "plt.ylabel(\"amount in messages\")\n",
        "plt.title(\"распределение amount-in-messages для негативных комментариев\")\n",
        "for p in hist_plot.patches:\n",
        "    height = p.get_height()\n",
        "    if height > 0:\n",
        "        ax.text(\n",
        "            p.get_x() + p.get_width() / 2,\n",
        "            height,\n",
        "            f'{height:.2f}',\n",
        "            ha='center',\n",
        "            va='bottom'\n",
        "        )\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mGfDU3yHnz7"
      },
      "source": [
        "Как можно видеть из этих графиков, львиная доля \"слов-маркеров\", по которым можно было бы отличать негативные комментарии от позитивных существуют в количестве менее 10 экземпляров, большая часть вообще существует в единственном экземпляре. Более того, даже самые популярные слова стречаются менее чем в 70 сообщениях (при общем объеме датасета в 10 000+ сообщений). Т.о. классифицировать данные просто по \"маркерам\" относительно бессмысленное занятие, так как при расширении датасета могут появиться сообщения без \"слов-маркеров\".\n",
        "\n",
        "Заметим также, что в neg_pos_df наиболее часто встречающиеся в комментариях слова встречаются практически с одинаковой вероятностью как в положительных, так и в отрицательных комментариях. Соответственно самые частовстречающиеся и самые одинаково распределённые слова, такие как \"на\", \"и\",... можно удалить как шум."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ldt1OnhxynQ1"
      },
      "outputs": [],
      "source": [
        "stop_words_df = neg_pos_df[(neg_pos_df['all-comments-amount'] > 1500)&\n",
        "                           (neg_pos_df['more-negative'] > 0.75)&\n",
        "                           (neg_pos_df['more-positive'] > 0.75)]\n",
        "stop_words = set(stop_words_df[\"words\"])\n",
        "#Слова, которые можно будет не учитывать\n",
        "# stop_words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3dgVTZ1jvkl"
      },
      "source": [
        "---\n",
        "# ***Выполним тематическое моделирование***.\n",
        "\n",
        " ***BERTopic***. Выбор обусловлен тем, что весь набор данных достаточно большой для этой модели, однако сами тексты довольно короткие, из-за чего ряд других моделей, например, ***LDA*** покажет худшие результаты, в сравнении с ***BERTopic***.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40jhzxkmAZpd"
      },
      "outputs": [],
      "source": [
        "def clean_from_stop_words(text):\n",
        "    approved = set(text) - stop_words\n",
        "    text = \" \".join([t for t in text if t in approved])\n",
        "    return text\n",
        "\n",
        "\n",
        "berk_text = df['clean-text'].apply(clean_from_stop_words)\n",
        "df['for-berk'] = berk_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVu8YthqKzMo"
      },
      "outputs": [],
      "source": [
        "!pip install huggingface_hub[hf_xet] #Вроде как так должно работать быстрее"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iC0n14V8CyqD"
      },
      "outputs": [],
      "source": [
        "from bertopic import BERTopic\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import umap\n",
        "import hdbscan\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "embedding_model = SentenceTransformer(\"ai-forever/sbert_large_mt_nlu_ru\")\n",
        "topic_model = BERTopic(\n",
        "    language=\"russian\",\n",
        "    umap_model=umap.UMAP(n_neighbors=2, min_dist=0.2, n_components=2, metric='cosine'),\n",
        "    hdbscan_model=hdbscan.HDBSCAN(min_cluster_size=5, metric='chebyshev')\n",
        ")\n",
        "\n",
        "topics, probs = topic_model.fit_transform(berk_text.to_list())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgpnmR5Bf_uW"
      },
      "outputs": [],
      "source": [
        "# Посмотрим таблицу с темами\n",
        "topic_info = pd.DataFrame(topic_model.get_topic_info())\n",
        "topic_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMaJaFUgOPsn"
      },
      "outputs": [],
      "source": [
        "topic_model.visualize_topics()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Варианты  дальнейшего улучшения тематического моделирования***\n",
        "\n",
        "\n",
        "1.   Подбор параметров в **umap_model** и **hdbscan_model** для уменьшения количества \"мусорных\" данных.\n",
        "2.  Можно попробовать *Мультикорпусное сравнение*: обучить на разных выборках и сравнить наборы.\n",
        "\n"
      ],
      "metadata": {
        "id": "neEI5B6_yMUK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# ***Обучение классификатора.***\n",
        "\n",
        "Построим модель в *PyTorch*.\n",
        "\n",
        "\n",
        "\n",
        "*   В качестве модели нейронной сети будет использоваться *GRU*, (Gated Recurrent Unit), так как он является одним из типов рекуррентных нейронных сетей (*RNN*), предназначенных для обработки последовательных данных, таких как текст. *GRU* является более легковесной и вычислительно эффективной моделью по сравнению с более сложным *LSTM*, однако в задачах классификации текса чатсо показывает результаты на уровне *LSTM*.\n",
        "\n",
        "*  В качестве критерия оценки качества будет использоваться *accuracy*, так как эта метрика используется в большинстве задач классификации и при этом легко интерпретируется: доля правильных ответов. Поэтому выбор пал  именно на неё, хотя *Precision*, *Recall* или *F1-score* также могли бы использоваться.\n",
        "\n",
        "*  В качестве функции потерь берёся *BCEWithLogitsLoss*, так как на данный момент считается предпочтительной в задачах бинарной классификации.\n",
        "\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "rvKMt_0k0A9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.optim as optim\n",
        "from torch.nn import functional as F\n"
      ],
      "metadata": {
        "id": "GRsd1AyF0kay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Для работы с lstm моделями нужно подавать не сообщения, а массивы слов\n",
        "df['for-lstm'] =  df['for-berk'].str.split()\n",
        "df"
      ],
      "metadata": {
        "id": "4vq0yvBC18Xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "texts =  df['for-lstm'].to_list()\n",
        "labels =  df['toxic'].to_list()\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    texts, labels, test_size=0.3, random_state=42, stratify=labels\n",
        ")\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.3, random_state=42, stratify=y_temp\n",
        ")"
      ],
      "metadata": {
        "id": "MZu9pTpt6Whi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Головная боль -- сообщения все разной длины. Нужно использовать padding. В качестве MaxLen буду брать 95-й порцентиль."
      ],
      "metadata": {
        "id": "d9ApkEAO6B9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lens = [len(x) for x in X_train]\n",
        "max_len = int(np.round(np.percentile(lens, 95)) + 1)\n",
        "max_len"
      ],
      "metadata": {
        "id": "f65xzdvK3-TJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Прелесть keras -- совместимость с numpy\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "dOoNWQVCaJZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " def tokenizing_fn(X_train, X_val, X_test, num_words=2000):\n",
        "    tokenizer = Tokenizer(num_words=num_words, oov_token=\"<OOV>\")\n",
        "    tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "    #tokenizing\n",
        "    train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "    val_seq = tokenizer.texts_to_sequences(X_val)\n",
        "    test_seq = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "    return train_seq, val_seq, test_seq\n",
        "\n",
        "def padding_fn(train_seq, val_seq, test_seq):\n",
        "    # 3. Padding\n",
        "    train_pad_seq = pad_sequences(train_seq, padding='post', maxlen=max_len)\n",
        "    val_pad_seq = pad_sequences(val_seq, padding='post', maxlen=max_len)\n",
        "    test_pad_seq = pad_sequences(test_seq, padding='post', maxlen=max_len)\n",
        "\n",
        "    return train_pad_seq, val_pad_seq, test_pad_seq\n",
        "\n",
        "\n",
        "\n",
        "def tokenizing_and_padding_fn(X_train, X_val, X_test, num_words=2000):\n",
        "    train_seq, val_seq, test_seq = tokenizing_fn(X_train, X_val, X_test, num_words=num_words)\n",
        "    return padding_fn(train_seq, val_seq, test_seq)"
      ],
      "metadata": {
        "id": "kOjqGhoH8sgX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GRU** model"
      ],
      "metadata": {
        "id": "9lDK2CQnEaos"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GRUClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, pad_idx, num_layers=2):\n",
        "        super(GRUClassifier, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
        "        # self.dropout = nn.Dropout(0.2)\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers=2, dropout=0.1, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        # embedded = self.dropout(embedded)\n",
        "        gru_out, _ = self.gru(embedded)\n",
        "\n",
        "        hidden = gru_out[:, -1, :]\n",
        "\n",
        "        output = self.fc(hidden)\n",
        "        # output = torch.sigmoid(output)\n",
        "        return output"
      ],
      "metadata": {
        "id": "w4TMOkTuEeHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Datasets & Dataloaders"
      ],
      "metadata": {
        "id": "Rc54IY-kAA5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def do_dataloaders(train_data, train_labels, val_data,\n",
        "                   val_labels, test_data, test_labels, device='cpu'):\n",
        "\n",
        "    train_data = torch.tensor(train_data, dtype=torch.long).to(device)\n",
        "    val_data = torch.tensor(val_data, dtype=torch.long).to(device)\n",
        "    test_data = torch.tensor(test_data, dtype=torch.long).to(device)\n",
        "\n",
        "    train_labels = torch.tensor(train_labels, dtype=torch.float32).to(device)\n",
        "    val_labels = torch.tensor(val_labels, dtype=torch.float32).to(device)\n",
        "    test_labels = torch.tensor(test_labels, dtype=torch.float32).to(device)\n",
        "\n",
        "    train_dataset = TensorDataset(train_data, train_labels)\n",
        "    val_dataset   = TensorDataset(val_data, val_labels)\n",
        "    test_dataset  = TensorDataset(test_data, test_labels)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "    test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n",
        ""
      ],
      "metadata": {
        "id": "5GUL3ThxAFG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train and validate model"
      ],
      "metadata": {
        "id": "v2iJcKuFFR5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time"
      ],
      "metadata": {
        "id": "arLcDPm9j2zi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def calculate_accuracy(predictions, labels):\n",
        "    predicted_labels = (predictions > 0.5).float()\n",
        "    correct = (predicted_labels == labels.view(-1, 1)).sum().item()\n",
        "    accuracy = correct / labels.size(0)\n",
        "    return accuracy\n",
        "\n",
        "def train_and_validate(model, train_loader, val_loader, epochs, device='cpu'):\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    acc_train_hist = []\n",
        "    acc_val_hist = []\n",
        "    start_time = time.time()\n",
        "    for epoch in range(epochs):\n",
        "        if epoch > 2:\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] = 0.0005\n",
        "        # Тренировка\n",
        "        model.train()\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "\n",
        "        for batch_X, batch_y in train_loader:\n",
        "            batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(batch_X)\n",
        "            loss = criterion(predictions, batch_y.view(-1, 1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_accuracy = calculate_accuracy(torch.sigmoid(predictions), batch_y)\n",
        "            train_correct += (train_accuracy * batch_y.size(0))\n",
        "            train_total += batch_y.size(0)\n",
        "\n",
        "        train_accuracy = train_correct / train_total\n",
        "        acc_train_hist.append(train_accuracy)\n",
        "\n",
        "        # Валидация\n",
        "        model.eval()\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_X, batch_y in val_loader:\n",
        "                batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "\n",
        "                predictions = model(batch_X)\n",
        "                val_accuracy = calculate_accuracy(torch.sigmoid(predictions), batch_y)\n",
        "                val_correct += (val_accuracy * batch_y.size(0))\n",
        "                val_total += batch_y.size(0)\n",
        "\n",
        "        val_accuracy = val_correct / val_total\n",
        "        acc_val_hist.append(val_accuracy)\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], \"\n",
        "              f\"Train Accuracy: {train_accuracy:.4f}, \"\n",
        "              f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
        "    end_time = time.time()\n",
        "    print(f\"TIME is {end_time-start_time:.4f} on device={device}\")\n",
        "    return acc_train_hist, acc_val_hist, model\n"
      ],
      "metadata": {
        "id": "DM0kbwWsFUWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_accuracy_score(test_dataloader, model, device):\n",
        "    model.eval()\n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "    for batch_X, batch_y in test_dataloader:\n",
        "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
        "        predictions = model(batch_X)\n",
        "        train_accuracy = calculate_accuracy(torch.sigmoid(predictions), batch_y)\n",
        "        test_correct += (train_accuracy * batch_y.size(0))\n",
        "        test_total += batch_y.size(0)\n",
        "\n",
        "    test_accuracy = test_correct / test_total\n",
        "    print(f\"TEST accuracy = {test_accuracy:.4f} on device={device}\")\n"
      ],
      "metadata": {
        "id": "4ll7Fplbo9YN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "histories = {}\n",
        "\n",
        "def modeling(X_train, X_val, X_test, device):\n",
        "    vocab_size = 2500\n",
        "    # padding\n",
        "    train_pad_seq, val_pad_seq, test_pad_seq = tokenizing_and_padding_fn(X_train, X_val, X_test, num_words=vocab_size)\n",
        "    # dataloaders\n",
        "    train_loader, val_loader, test_loader = do_dataloaders(train_pad_seq, y_train, val_pad_seq, y_val, test_pad_seq, y_test, device=device)\n",
        "    # model\n",
        "    model = GRUClassifier(vocab_size=vocab_size, embedding_dim=128, hidden_dim=64, output_dim=1, pad_idx=0).to(device)\n",
        "    # training\n",
        "    train_hist, val_hist, model = train_and_validate(model, train_loader, val_loader, epochs=10, device=device)\n",
        "    # testing\n",
        "    test_accuracy_score(test_loader, model, device)\n",
        "    return train_hist, val_hist\n",
        "\n",
        "\n",
        "train_hist, val_hist = modeling(X_train, X_val, X_test, 'cuda')\n",
        "histories['cuda train'] = train_hist\n",
        "histories['cuda val'] =  val_hist\n",
        "train_hist, val_hist = modeling(X_train, X_val, X_test, 'cpu')\n",
        "histories['cpu train'] = train_hist\n",
        "histories['cpu val'] =  val_hist"
      ],
      "metadata": {
        "id": "XKRS6qpMDUnV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Визуализация обучения"
      ],
      "metadata": {
        "id": "VsmPXE0qh_uL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(histories['cpu train'], label=\"Train Accuracy\")\n",
        "plt.plot(histories['cpu val'] , label=\"Val Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"График Accuracy для расчётов на CPU\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8A9h-eTBiC7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(histories['cuda train'], label=\"Train Accuracy\")\n",
        "plt.plot(histories['cuda val'] , label=\"Val Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"График Accuracy для расчётов на CUDA\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TkQPZ1GXsJyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# *Что можно улучшить?*\n",
        "\n",
        "\n",
        "1.   Использование предобученных эмбеддингов, таких как *Word2Vec* или *BERT*.\n",
        "2.   Увеличение данных (Data Augmentation).\n",
        "3.   Вместо GRU можно попробовать более сложные архитектуры, такие как *transformers*.\n",
        "4.   Auto ML. Использовать методы подбора гипперпараметров, такие как optuna лдя выбора оптимальных параметров *learning rate*, *vocab_size*, *dropout*, *embedding_dim*.\n",
        "4.   Дополнительная оптимизация *learning rate*: требуется вручную уменьшать его, чтобы избегать переобучения\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "3-P1eEyXdlv-"
      }
    }
  ],
  "metadata": {
    "colab": {
      "cell_execution_strategy": "setup",
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyO2tjZnYZXXYuQVEXBNYYiU",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}